# ğŸ¾ ResNet-101: ClasificaciÃ³n de Gato vs Perro con Interpretabilidad

Repositorio de una aplicaciÃ³n completa (API + App) que implementa **ResNet-101** en PyTorch para clasificar imÃ¡genes de **gatos** y **perros**, e incorpora un mÃ³dulo de **interpretabilidad** para entender â€œquÃ© veâ€ la red en cada predicciÃ³n. El foco es proporcionar una herramienta avanzada de clasificacion y entendimiento con codigo altamente reproducible: cÃ³digo modular, configuraciÃ³n por YAML y utilidades de evaluaciÃ³n/visualizaciÃ³n.

---

## ğŸ¯ Objetivos

- **ClasificaciÃ³n binaria** (cat vs dog) sobre imÃ¡genes del usuario (archivo local o URL).
- **Interpretabilidad avanzada** para inspeccionar la decisiÃ³n del modelo en cada imagen:
  - **Occlusion Sensitivity**: relevancia por parches.
  - **Integrated Gradients**: atribuciones acumuladas desde una referencia.
  - **Grad-CAM**: mapa de calor clase-especÃ­fico.
  - **Feature Maps (depth)**: activaciones intermedias por capa.
  - **Kernels (depth)**: filtros aprendidos (p. ej., Conv1).

---

## ğŸ§© Componentes principales

- **`resnet101/`**: implementaciÃ³n del modelo (desde cero) y artefactos de experimentos.
  - `src/` â€“ arquitectura, bloques residuales, utilidades de guardado.
  - `model_trained/` â€“ pesos entrenados.
  - `experiments/` â€“ resultados y paneles generados.

- **`src/`**: API de inferencia (FastAPI) y utilidades.
  - `api/` â€“ routers (`/health`, `/predict`, `/predict/advanced`), errores, middleware, deps.
  - `inference/` â€“ pipeline de preprocesamiento â†’ forward â†’ postprocesado â†’ validaciÃ³n.
  - `schemas/` â€“ contratos Pydantic v2 para requests/responses (incluye metadatos e imÃ¡genes base64).
  - `utils/` â€“ configuraciÃ³n, lectura de variables de entorno, paths, etc.
  - `tests/` â€“ pruebas de contrato y validaciones de entrada (pytest).

- **`app/`**: interfaz de usuario (Streamlit) para subir imÃ¡genes/URLs y explorar explicaciones.

- **`data/`**: preparaciÃ³n de datos y estadÃ­sticas.
  - `processed/` â€“ carpeta de trabajo (no versionar datos brutos).
  - `pet_stats.json` â€“ medias/desviaciones para normalizaciÃ³n reproducible.

- **`notebooks/`**: verificaciÃ³n de flujo de datos y sanity checks del modelo.

- **`oxford_pets_binary_resnet101.yaml`**: configuraciÃ³n del experimento (datos, modelo, optimizador, scheduler, device).

---

## ğŸ–¼ï¸ Showcase 

**Vista general de la App (Home / Subida de imagen):**  

<div align="center">
  <img src="app/showcase/Showcase app.png" alt="showcase app" width="620">
</div>

---

**PredicciÃ³n avanzada (Interpretabilidad por mÃ©todo):**

<!-- 1) Grad-CAM centrado solo -->
<div align="center">
  <strong>Grad-CAM</strong><br>
  <img src="advance_visualization/samples/Grad Cam.png" alt="Grad-CAM" width="620"><br>
  <sub>Mapa de calor clase-especÃ­fico.</sub>
</div>

---

<!-- 2) Fila: Occlusion | Integrated, ambos centrados -->
<div align="center">
  <table>
    <tr>
      <td align="center" style="padding:12px;">
        <strong>Occlusion Sensitivity</strong><br>
        <img src="advance_visualization/samples/oclusion v2.png" alt="Occlusion Sensitivity" width="360"><br>
        <sub>Importancia local al ocultar parches.</sub>
      </td>
      <td align="center" style="padding:12px;">
        <strong>Integrated Gradients (overlay)</strong><br>
        <img src="advance_visualization/samples/Integrated Gradients.png" alt="Integrated Gradients overlay" width="360"><br>
        <sub>Atribuciones acumuladas superpuestas.</sub>
      </td>
    </tr>
  </table>
</div>

---

<!-- 3) Feature Maps centrado -->
<div align="center">
  <strong>Feature Maps (profundidad/capas)</strong><br>
  <img src="advance_visualization/samples/Feature Maps.png" alt="Feature Maps" width="620"><br>
</div>

<!-- 4) Kernels centrado -->
<div align="center" style="padding-top:8px;">
  <strong>Kernels (filtros aprendidos)</strong><br>
  <img src="advance_visualization/samples/Filters.png" alt="Kernels aprendidos" width="620"><br>
  <sub>Filtros de capas tempranas (bordes, texturas, orientaciones).</sub>
</div>


---

## ğŸ” Flujo de inferencia

1. **Entrada**: archivo o URL â†’ validaciÃ³n (MIME/shape).
2. **Preprocesamiento**: resize/center-crop â†’ tensor normalizado (estadÃ­sticos cacheados).
3. **Modelo (ResNet-101)**: forward â†’ logits â†’ softmax.
4. **Salida bÃ¡sica**: `label` + `scores` + `meta`.
5. **Salida avanzada**: aÃ±ade `artifacts` con paneles (PNG base64) para:
   - `gradcam_panel`
   - `integrated_gradients_overlay`
   - `occlusion_overlay`
   - `feature_maps_panel`
   - `kernels_panel`
   (e indicadores de error por panel si aplica.)

---

## ğŸ§  Interpretabilidad (resumen conceptual)

- **Grad-CAM**: resalta zonas espacialmente relevantes para la clase objetivo a partir de gradientes de capas profundas.
- **Integrated Gradients**: atribuye importancia a cada pÃ­xel integrando el gradiente a lo largo de un camino desde una referencia (baseline) hasta la imagen.
- **Occlusion Sensitivity**: mide cÃ³mo cambia la confianza al â€œocultarâ€ parches de la imagen (bÃºsqueda local de relevancia).
- **Feature Maps**: muestran quÃ© patrones intermedios activan las capas (texturas, bordes, partes).
- **Kernels**: visualiza filtros aprendidos en convoluciones (especialmente capas tempranas).

---

## ğŸ“Š MÃ©tricas de referencia (validaciÃ³n)

- PÃ©rdida (Val Loss)
- ROC-AUC
- Reporte de clasificaciÃ³n (PrecisiÃ³n/Recall/F1 por clase)
- Matriz de confusiÃ³n

[ESPACIO RESERVADO PARA TABLA/FIGURA DE MÃ‰TRICAS]

---

## ğŸ” Pesos y datos

- Los **pesos del modelo** pueden distribuirse por **Git LFS** o alojarse externamente (HuggingFace/Drive) y enlazarse en el README.
- Los **datos** deben respetar sus licencias; este proyecto usa **Oxford-IIIT Pet** con fines educativos.

---

## ğŸ—ºï¸ Rutas expuestas (API)

- `GET /health` â†’ Estado del servicio.
- `POST /predict` â†’ PredicciÃ³n base: `label`, `scores`, `meta`.
- `POST /predict/advanced` â†’ PredicciÃ³n + `artifacts` de interpretabilidad.

[ESPACIO RESERVADO PARA EJEMPLOS DE REQUEST/RESPONSE]

---

## âš™ï¸ Reproducibilidad

- ConfiguraciÃ³n centralizada en **YAML** (dataset, normalizaciÃ³n, arquitectura, optimizador, scheduler).
- EstadÃ­sticos de normalizaciÃ³n cacheados en `data/pet_stats.json`.
- Semillas y dispositivos controlados (CPU/CUDA).

---

## ğŸ§­ Roadmap

- ExportaciÃ³n ONNX/TorchScript.
- Batch inference por carpeta/URL list.
- Panel de interpretabilidad adicional (SmoothGrad, Grad-CAM++).  
- Tests mÃ¡s exhaustivos de contrato y regresiÃ³n visual.

---

## ğŸ“„ Licencia y crÃ©ditos

- Uso **educativo y de investigaciÃ³n**.
- Cita sugerida a **He et al. (2015)** por ResNet y a los trabajos originales de interpretabilidad correspondientes.
- Agradecimientos a la comunidad PyTorch y al dataset Oxford-IIIT Pet.

---

## ğŸ“¬ Contacto

- Issues y mejoras: usar el **Issue Tracker** del repositorio.
- Preguntas tÃ©cnicas: abrir un **Discussion** con el tag `help-wanted`.
